# Navigate to your project
cd horse_racing_predictor

# Edit the file (replace the content with the new code)
# You can use any text editor like nano, vim, or VS Code
nano predictor.py

# Add and commit changes
git add predictor.py
git commit -m "Enhanced odds extraction with multiple fallback 
methods"

# Push to GitHub
git push origin mimport time
import re
from bs4 import BeautifulSoup
import requests
import os


def extract_win_percent_from_jockey_tooltip(hpop0_html):
    soup = BeautifulSoup(hpop0_html, "html.parser")
    text = soup.get_text(" ", strip=True)
    match = re.search(r'\d+\s+wins\s+in\s+\d+\s+runs\s*\((\d{1,3})%\)', text)
    return int(match.group(1)) if match else 0


def extract_odds(row):
    """
    Enhanced odds extraction with multiple fallback methods
    """
    # Method 1: Original approach
    odds_tag = row.find("span", class_="bkprice")
    if odds_tag and odds_tag.get_text(strip=True):
        return odds_tag.get_text(strip=True)
    
    # Method 2: Try different common odds class names
    odds_classes = ["odds", "price", "bk-price", "bookmaker-price", "betting-odds", "runner-odds"]
    for cls in odds_classes:
        odds_tag = row.find("span", class_=cls)
        if odds_tag and odds_tag.get_text(strip=True):
            return odds_tag.get_text(strip=True)
    
    # Method 3: Look for odds patterns in any span or div
    all_spans = row.find_all(["span", "div"])
    for span in all_spans:
        text = span.get_text(strip=True)
        # Look for common odds formats: 3/1, 5-2, 2.50, evens
        if re.match(r'^\d+/\d+$|^\d+-\d+$|^\d+\.\d+$|^evens?$|^fav$', text, re.IGNORECASE):
            return text
    
    # Method 4: Look for data attributes that might contain odds
    odds_data_attrs = ["data-odds", "data-price", "data-bk-price"]
    for attr in odds_data_attrs:
        if row.get(attr):
            return row.get(attr)
    
    # Method 5: Look in nested elements with odds-related attributes
    odds_elements = row.find_all(attrs={"data-odds": True}) + \
                   row.find_all(attrs={"data-price": True}) + \
                   row.find_all(class_=re.compile(r'odds|price', re.I))
    
    for elem in odds_elements:
        if elem.get_text(strip=True):
            return elem.get_text(strip=True)
        # Check data attributes
        for attr in ['data-odds', 'data-price', 'data-bk-price']:
            if elem.get(attr):
                return elem.get(attr)
    
    return "N/A"


def debug_html_structure(row, horse_name):
    """
    Debug function to print HTML structure for troubleshooting
    """
    print(f"\n--- DEBUG: HTML structure for {horse_name} ---")
    print("All spans with text:")
    spans = row.find_all("span")
    for i, span in enumerate(spans):
        text = span.get_text(strip=True)
        classes = span.get('class', [])
        if text:  # Only show spans with content
            print(f"  Span {i}: '{text}' | Classes: {classes}")
    
    print("All divs with text:")
    divs = row.find_all("div")
    for i, div in enumerate(divs):
        text = div.get_text(strip=True)
        classes = div.get('class', [])
        if text and len(text) < 50:  # Only show short divs with content
            print(f"  Div {i}: '{text}' | Classes: {classes}")
    print("--- END DEBUG ---\n")


def launch_browser_get_html(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    session = requests.Session()
    session.headers.update(headers)
    
    try:
        response = session.get(url, timeout=15)
        response.raise_for_status()
        
        # Add a small delay to mimic human behavior
        time.sleep(1)
        
        return response.text
    except requests.exceptions.RequestException as e:
        print(f"Request failed: {e}")
        raise
    finally:
        session.close()


def parse_racecard(html, debug_mode=False):
    soup = BeautifulSoup(html, "html.parser")
    horse_rows = soup.find_all("div", class_="runner-line")
    horses = []

    if debug_mode and horse_rows:
        print(f"Found {len(horse_rows)} horse rows")
        # Debug first horse to understand structure
        debug_html_structure(horse_rows[0], "First Horse")

    for row in horse_rows:
        try:
            horse = {}

            # Horse name
            name_tag = row.find("a", class_="runner")
            horse["name"] = name_tag.get_text(strip=True) if name_tag else "Unknown"

            # Form
            form_tag = row.find("div", class_="form")
            horse["form"] = form_tag.text.strip() if form_tag else ""

            # CD win
            horse["cd_win"] = 1 if row.select_one("span.cdwin") else 0

            # Rating
            rating_tag = row.find("span", string=re.compile("Rated"))
            horse["rating"] = int(rating_tag.text.strip().replace("Rated", "").strip()) if rating_tag else 0

            # Trainer
            trainer_tag = row.find("a", href=re.compile("/trainer/"))
            horse["trainer"] = trainer_tag.get_text(strip=True) if trainer_tag else "Unknown"
            horse["trainer_win_pct"] = 0  # Not available

            # Jockey
            jockey_tag = row.find("a", href=re.compile("/jockey/"))
            jockey_name = jockey_tag.get_text(strip=True) if jockey_tag else "Unknown"
            jockey_data = jockey_tag.get("data-hpop0", "") if jockey_tag else ""
            horse["jockey"] = jockey_name
            horse["jockey_win_pct"] = extract_win_percent_from_jockey_tooltip(jockey_data)

            # Odds (enhanced extraction)
            horse["odds"] = extract_odds(row)

            horses.append(horse)

        except Exception as e:
            print(f"⚠️ Skipping horse due to error: {e}")
            continue

    return horses


def score_horse(h):
    score = 0

    # Form scoring
    score += h["form"].count("1") * 5
    score += h["form"].count("2") * 3
    score += h["form"].count("3") * 2

    # CD win
    score += h["cd_win"] * 3

    # Rating
    score += h["rating"] / 10

    # Jockey (light weight)
    score += h["jockey_win_pct"] * 0.25

    return score


def save_debug_html(html, filename="debug_racecard.html"):
    """Save HTML to file for manual inspection"""
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(html)
    print(f"Debug HTML saved to {filename}")


def main():
    url = input("🔗 Enter IrishRacing racecard URL: ").strip()
    
    # Ask if user wants debug mode
    debug_input = input("Enable debug mode? (y/n): ").strip().lower()
    debug_mode = debug_input == 'y'
    
    html = launch_browser_get_html(url)
    
    if debug_mode:
        save_debug_html(html)
    
    horses = parse_racecard(html, debug_mode)

    if not horses:
        print("❌ No horses found.")
        return

    for horse in horses:
        horse["score"] = score_horse(horse)

    ranked = sorted(horses, key=lambda x: x["score"], reverse=True)

    print("\n🏇 Predicted Order:")
    for i, h in enumerate(ranked, 1):
        print(f"{i}. {h['name']} - Score: {h['score']:.1f} | "
              f"Form: {h['form']} | CD Win: {'Yes' if h['cd_win'] else 'No'} | "
              f"Rating: {h['rating']} | Jockey: {h['jockey']} ({h['jockey_win_pct']}%) | "
              f"Odds: {h['odds']}")

    print(f"\n🥇 Most Likely Winner: {ranked[0]['name']}")
    
    # Show odds extraction summary
    odds_found = sum(1 for h in horses if h['odds'] != 'N/A')
    print(f"\n📊 Odds found for {odds_found}/{len(horses)} horses")


if __name__ == "__main__":
    main()






























